{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\datasets\\homeprices.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08827586, 0.25      ],\n",
       "       [0.62068966, 0.75      ],\n",
       "       [0.22068966, 0.5       ],\n",
       "       [0.24862069, 0.5       ],\n",
       "       [0.13793103, 0.25      ],\n",
       "       [0.12758621, 0.25      ],\n",
       "       [0.6662069 , 0.75      ],\n",
       "       [0.86206897, 0.75      ],\n",
       "       [0.17586207, 0.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [0.34482759, 0.5       ],\n",
       "       [0.68448276, 0.75      ],\n",
       "       [0.06896552, 0.25      ],\n",
       "       [0.10344828, 0.25      ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.12931034, 0.25      ],\n",
       "       [0.13103448, 0.5       ],\n",
       "       [0.25517241, 0.5       ],\n",
       "       [0.67931034, 0.5       ],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "sx = preprocessing.MinMaxScaler()\n",
    "sy = preprocessing.MinMaxScaler()\n",
    "\n",
    "scaled_X = sx.fit_transform(df.drop('price', axis='columns'))\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05237037],\n",
       "       [0.65185185],\n",
       "       [0.22222222],\n",
       "       [0.31851852],\n",
       "       [0.14074074],\n",
       "       [0.04444444],\n",
       "       [0.76296296],\n",
       "       [0.91111111],\n",
       "       [0.13333333],\n",
       "       [1.        ],\n",
       "       [0.37037037],\n",
       "       [0.8       ],\n",
       "       [0.04444444],\n",
       "       [0.05925926],\n",
       "       [0.51111111],\n",
       "       [0.07407407],\n",
       "       [0.11851852],\n",
       "       [0.20740741],\n",
       "       [0.51851852],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_y = sy.fit_transform(df['price'].values.reshape(df.shape[0],1))\n",
    "scaled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70712464, 0.67456527]), -0.23034857438407427, 0.0068641890429808105)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\n",
    "\n",
    "    number_of_features = X.shape[1]\n",
    "    # numpy array with 1 row and columns equal to number of features. In \n",
    "    # our case number_of_features = 2 (area, bedroom)\n",
    "    w = np.ones(shape=(number_of_features)) \n",
    "    b = 0\n",
    "    total_samples = X.shape[0] # number of rows in X\n",
    "    \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(epochs):        \n",
    "        y_predicted = np.dot(w, X.T) + b\n",
    "\n",
    "        w_grad = -(2/total_samples)*(X.T.dot(y_true-y_predicted))\n",
    "        b_grad = -(2/total_samples)*np.sum(y_true-y_predicted)\n",
    "        \n",
    "        w = w - learning_rate * w_grad\n",
    "        b = b - learning_rate * b_grad\n",
    "        \n",
    "        cost = np.mean(np.square(y_true-y_predicted)) # MSE (Mean Squared Error)\n",
    "        \n",
    "        if i%10==0:\n",
    "            cost_list.append(cost)\n",
    "            epoch_list.append(i)\n",
    "        \n",
    "    return w, b, cost, cost_list, epoch_list\n",
    "\n",
    "w, b, cost, cost_list, epoch_list = batch_gradient_descent(scaled_X,scaled_y.reshape(scaled_y.shape[0],),500)\n",
    "w, b, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.45484403267596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(area, bedrooms, w, b):\n",
    "    scaled_X = sx.transform([[area, bedrooms]])[0]\n",
    "    \n",
    "    scaled_price = w[0]*scaled_X[0]+w[1]*scaled_X[1]+b\n",
    "    return sy.inverse_transform([[scaled_price]])[0][0]\n",
    "\n",
    "predict(2600,4,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70786941, 0.67260472]), -0.23613476390514246, 0.00405481236912506)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\n",
    " \n",
    "    number_of_features = X.shape[1]\n",
    "    # numpy array with 1 row and columns equal to number of features. In \n",
    "    # our case number_of_features = 3 (area, bedroom and age)\n",
    "    w = np.ones(shape=(number_of_features)) \n",
    "    b = 0\n",
    "    total_samples = X.shape[0]\n",
    "    \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(epochs):    \n",
    "        random_index = random.randint(0,total_samples-1) # random index from total samples\n",
    "        sample_x = X[random_index]\n",
    "        sample_y = y_true[random_index]\n",
    "        \n",
    "        y_predicted = np.dot(w, sample_x.T) + b\n",
    "    \n",
    "        w_grad = -(2/total_samples)*(sample_x.T.dot(sample_y-y_predicted))\n",
    "        b_grad = -(2/total_samples)*(sample_y-y_predicted)\n",
    "        \n",
    "        w = w - learning_rate * w_grad\n",
    "        b = b - learning_rate * b_grad\n",
    "        \n",
    "        cost = np.square(sample_y-y_predicted)\n",
    "        \n",
    "        if i%100==0: # at every 100th iteration record the cost and epoch value\n",
    "            cost_list.append(cost)\n",
    "            epoch_list.append(i)\n",
    "        \n",
    "    return w, b, cost, cost_list, epoch_list\n",
    "\n",
    "w_sgd, b_sgd, cost_sgd, cost_list_sgd, epoch_list_sgd = stochastic_gradient_descent(scaled_X,scaled_y.reshape(scaled_y.shape[0],),10000)\n",
    "w_sgd, b_sgd, cost_sgd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.53760966126646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2600,4,w_sgd,b_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 17,  3,  5, 10,  1,  6,  4, 12, 18,  7, 15, 14,  0,  8, 16, 11,\n",
       "       19,  9, 13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.71012916, 0.67815997]), -0.23339846034450204, 0.01740785933694305)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mini_batch_gradient_descent(X, y_true, epochs, batch_size, learning_rate = 0.01):\n",
    "    number_of_features = X.shape[1]\n",
    "    # numpy array with 1 row and columns equal to number of features. In \n",
    "    # our case number_of_features = 3 (area, bedroom and age)\n",
    "    w = np.ones(shape=(number_of_features)) \n",
    "    b = 0\n",
    "    total_samples = X.shape[0]\n",
    "    \n",
    "    if batch_size > total_samples:\n",
    "        batch_size = total_samples\n",
    "        \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    num_batches = int(total_samples/batch_size)\n",
    "    \n",
    "    for i in range(epochs):    \n",
    "        random_indices = np.random.permutation(total_samples)\n",
    "        X_tmp = X[random_indices]\n",
    "        y_tmp = y_true[random_indices]\n",
    "        \n",
    "        for j in range(0,total_samples,batch_size):\n",
    "            Xj = X_tmp[j:j+batch_size]\n",
    "            yj = y_tmp[j:j+batch_size]\n",
    "            y_predicted = np.dot(w, Xj.T) + b\n",
    "            \n",
    "            w_grad = -(2/len(Xj))*(Xj.T.dot(yj-y_predicted))\n",
    "            b_grad = -(2/len(Xj))*np.sum(yj-y_predicted)\n",
    "            \n",
    "            w = w - learning_rate * w_grad\n",
    "            b = b - learning_rate * b_grad\n",
    "                \n",
    "            cost = np.mean(np.square(yj-y_predicted)) # MSE (Mean Squared Error)\n",
    "        \n",
    "        if i%10==0:\n",
    "            cost_list.append(cost)\n",
    "            epoch_list.append(i)\n",
    "        \n",
    "    return w, b, cost, cost_list, epoch_list\n",
    "\n",
    "w_mgd, b_mgd, cost_mgd, cost_list_mgd, epoch_list_mgd = mini_batch_gradient_descent(\n",
    "    scaled_X,\n",
    "    scaled_y.reshape(scaled_y.shape[0],),\n",
    "    epochs = 120,\n",
    "    batch_size = 5\n",
    ")\n",
    "w_mgd, b_mgd, cost_mgd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.6588318305989"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2600,4,w_mgd,b_mgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
